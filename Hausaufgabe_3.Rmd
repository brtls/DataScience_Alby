---
title: "Hausaufgabe_3"
output: html_notebook
---
## Load libraries
```{r}
library(tidyverse)
library(readr)
library(arules)
library(arulesViz)
```

## Loading dataset
```{r}
all <- read_csv("All.csv")

all$X1 <- NULL
```


## Erstellen der Regeln

```{r}
i <- split(all$book_title, all$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0015, conf = 0.001, minlen = 2,
                        target = "rules"))
```
```{r}
myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)

plot(basket_rules_hi, method = "graph", main = "Books")
```
Die Ausgangswerte für support und confidence sind:

* sup = 0.0015
* conf = 0.001
* Rules = 97

Das heißt: Wir lassen uns Regeln dazu Erstellen, dass wenn ein Buch bewertet wurde, ein Weiteres, was dann vermutlich mit Ersterem in Verbindung steht, auch bewertet wurde. Dabei geben wir mit sup = 0.15% vor, dass die Kombination zweier bewerteter Bücher mindestens in 0,15% der Fällen vorkommt. Mit einer Konfidenz von 0.1% geben wir vor, dass mit einer Wahrscheinlichkeit von mindestens 0.1% RHS vorkommt, wenn LHS vorliegt. Beispielsweise: Wenn "The Lord of the Rings, Part 2" vorliegt, kommt "The Lord of the Rings, Part 1" auch vor, in diesem Fall beträgt die Konfidenz 43,5%. D.h. wenn The Lord of the Rings, Part 2 bewertet wurde, wurde in 43,5% der Fälle auch The Lord of the Rings, Part 1 bewertet. 

```{r}
i <- split(all$book_title, all$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0025, conf = 0.001, minlen = 2,
                        target = "rules"))

myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)
```
Wenn wir nun die Werte für Support und Konfidenz verändern, verändert sich auch die Anzahl der ausgegeben Regeln. 
Bei einem sup = 0.25% und conf = 0.1% werden nur noch 8 Regeln erstellt. Da nur noch Bücher, welche in Kombination in >=0.25%  der Fällen berücksichtigt werden.Gehen wir mit dem Support weiter runter, wird sich die Anzahl der erstellbaren Regeln dem entsprechend vergrößern. 

```{r}
i <- split(all$book_title, all$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0015, conf = 0.8, minlen = 2,
                        target = "rules"))

myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)
```
Nun verändern wir die Konfidenz von 0.1% auf 80%. Dabei werden noch zwei Regeln gefunden. **Ergebnis** 88% der Leser, welche Harry Potter and the Goblet of Fire (Book 4) und Harry Potter and the Prisoner of Azkaban (Book 3) bewertet haben, haben auch Harry Potter and the Chamber of Secrets (Book 2) bewertet. 

#### Zurzeit haben wir bei Market Basket Analysis alle Bewertungen drin, gibt es eine bessere Lösung? 
Eine bessere Lösung mit genaueren Ergebnissen könnte sein, dass alle Bewertungen, welche 0 sind, also höchstwahrscheinlich keine Bewertung haben, herausgefiltert werden. 
```{r}
all_better_ratings <- all %>% 
  filter(book_rating > 0)

i <- split(all_better_ratings$book_title, all_better_ratings$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0015, conf = 0.001, minlen = 2,
                        target = "rules"))

myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)

plot(basket_rules_hi, method = "graph", main = "Books")
```
Nun kommen deutlich weniger Regeln heraus (9), welche genauer sein sollte, da die Bewertungen mit 0 herausgefiltert wurden. Wird der sup weiter nach unten angepassten, lassen sich wieder mehr Regeln finden. 

In der Grafik sind die einzelnen Regeln zusehen, welche sich aus den Items und Verbindungen zusammensetzen. Je höher der Support, desto größer der Kreis. Die roten kleinen Kreise stehen für ein Item, je dunkler der Kreis, desto höher der Lift. 

# Analyse mit Autoren in den Transaktionen

```{r}
i <- split(all$book_author, all$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0015, conf = 0.001, minlen = 2,
                        target = "rules"))

myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)
```
Es kommen sehr viel mehr Regeln heraus (70461) als in der ersten Transaktion. Wenn der Support erhöht wird, werden weniger Regeln gebildet, dafür wären diese umso aussagekräftiger, da mit dem Support bestimmt wird, wie häufig eine Kombination vorkommt. 

## Visualisierungen 
```{r}
plot(basket_rules_hi, method = "graph", main = "Autoren")
plot(basket_rules_hi, method="graph", main="Autoren", engine="interactive")
```

Wenn Autorennamen unterschiedlich geschrieben werden, aber die gleiche Person gemeint ist sollten diese Mehrfachnennungen heraus gefiltert werden. Dies fällt besonders in der Grafik auf, z.B. bei dem Autoren "Tim Lahaye" / "Tim LaHaye", sowie "Sophie Kinsella". Deswegen versuche ich mit Hilfe regulärer Ausdrücke die alle Autoren in iherer Schreibweise zu vereinheitlichen.
```{r}
all_filtert_authors <- all %>% 
  mutate(book_author = ifelse(grepl("[A-Z]{2}", book_author), str_to_title(book_author), book_author))

i <- split(all_filtert_authors$book_author, all_filtert_authors$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0015, conf = 0.001, minlen = 2,
                        target = "rules"))

myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)
```
```{r}
plot(basket_rules_hi, method = "graph", main = "Autoren")
```
Bei den meisten Autoren hat die Umwandlung in Kleinschreibung funktioniert, bei Tim LaHaye nicht, da der Nachname zusammengeschrieben ist.

### Wie kann man nun noch sicherstellen, dass nur die Autoren weiterempfohlen werden, deren Bücher man auch (mehrheitlich) gut fand? 
Zu nächst filtere ich wieder die Bewertungen raus, welche 0 sind. Im zweiten Schritt berechne ich die durchschnittliche Bewertung der Autoren, sowie die Anzahl der Bewertungen pro Autor. Diese filter ich nun nach guten Büchern (Durchschnitt von über 8), sowie einer Anzahl an Bewertungen von über 1000, sowie einem Support von 0.25%. Das Ergebnis sind 9 Regeln und 3 Autoren, welche diesen Ansprüchen gerecht werden. Diese sind laut List sehr Empfehlenswert zu lesen und haben wohl einige Gemeinsamkeiten.
```{r}

all_filtert_authors <- all_filtert_authors %>% 
  filter(book_rating > 0)

good_authors <- all_filtert_authors %>% 
  group_by(book_author) %>% 
  mutate(durchschnitts_bewertung = mean(book_rating), anzahl_bewertungen = n()) %>%
  select(book_author, user_id, book_title, durchschnitts_bewertung, anzahl_bewertungen) %>% 
  filter(durchschnitts_bewertung > 8, anzahl_bewertungen > 1000) %>% 
  unique()

```


```{r}
i <- split(good_authors$book_author, good_authors$user_id)
txn <- as(i, "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0.0025, conf = 0.001, minlen = 2,
                        target = "rules"))
```


```{r}
myRules_Direct <- as(basket_rules, "data.frame")
basket_rules_hi <- head(basket_rules, by = "lift", 100)
head(myRules_Direct, 20)
```
```{r}
plot(basket_rules_hi, method = "graph", main = "Autoren")
```

# Welche anderen Features wären sinnvoll? 

* Das durchschnittliche Alter der Leser (so könnt nochmal explizit zwischen Kinderbuchautoren und "normalen/erwachsenen" Autoren unterschieden werden, wenn die Bewerter genau der Autorenzielgruppe entsprechen). 
* Die Location der Leser wäre auch interessant zu wissen, um mögliche Sprachbarrieren vorzubeugen. 
* Mit Hilfe des Publikaitonsjahres könnten zudem explizit nach "neuen" Bücher gesucht werden.  


